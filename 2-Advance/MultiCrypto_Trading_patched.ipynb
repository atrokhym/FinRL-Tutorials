{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl3liTlqF2tZ"
   },
   "source": [
    "# Multiple Cryptocurrencies Trading Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph-kT4laFy5k"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVuCBw07AGgJ"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/MultiCrypto_Trading.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfKfNSTnEqsq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%cd /tmp\n",
    "#!git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "!git clone https://github.com/atrokhym/FinRL-Meta.git\n",
    "%cd FinRL-Meta/\n",
    "!pip install git+https://github.com/AI4Finance-Foundation/ElegantRL.git\n",
    "!pip install wrds\n",
    "!pip install swig\n",
    "# !pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
    "!pip install yfinance stockstats\n",
    "!pip install alpaca_trade_api\n",
    "!pip install ray[default]\n",
    "!pip install lz4\n",
    "!pip install ray[tune]\n",
    "!pip install tensorboardX\n",
    "!pip install gputil\n",
    "!pip install trading_calendars\n",
    "!pip install wrds\n",
    "!pip install rqdatac\n",
    "!pip install sqlalchemy==1.2.19\n",
    "!pip install tushare\n",
    "#install talib\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') \n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# os.chdir('../')\n",
    "!pip install TA-Lib\n",
    "!pip install baostock\n",
    "!pip install quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpUwP86TF9LE"
   },
   "source": [
    "## Import Related Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3W6tDA_FFGA",
    "outputId": "074304b8-c615-45a2-c6e1-7be01aecf9ca",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%cd /tmp/FinRL-Meta/\n",
    "from meta.env_crypto_trading.env_multiple_crypto import CryptoEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSDuv3R9H6Y5"
   },
   "source": [
    "## Functions for Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll create a script you can add to your notebook that automatically updates all Ray import paths in the FinRL-Meta code to be compatible with Ray 2.x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Find the installation directory of FinRL-Meta\n",
    "import inspect\n",
    "try:\n",
    "    # Try to import a module from FinRL-Meta to locate its path\n",
    "    from meta import data_processor\n",
    "    finrl_meta_path = Path(inspect.getfile(data_processor)).parent.parent\n",
    "    print(f\"Found FinRL-Meta at: {finrl_meta_path}\")\n",
    "except ImportError:\n",
    "    # If that fails, assume we're in the FinRL-Meta directory\n",
    "    finrl_meta_path = Path(\"./FinRL-Meta\")\n",
    "    if not finrl_meta_path.exists():\n",
    "        finrl_meta_path = Path(\".\")\n",
    "    print(f\"Using FinRL-Meta path: {finrl_meta_path}\")\n",
    "\n",
    "# Dictionary mapping old import paths to new ones\n",
    "import_replacements = {\n",
    "    \"from ray.rllib.agents.\": \"from ray.rllib.algorithms.\",\n",
    "    \"import ray.rllib.agents.\": \"import ray.rllib.algorithms.\",\n",
    "}\n",
    "\n",
    "# Function to process a file\n",
    "def update_ray_imports(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        original_content = content\n",
    "        for old_import, new_import in import_replacements.items():\n",
    "            content = content.replace(old_import, new_import)\n",
    "        \n",
    "        # Only write if changes were made\n",
    "        if content != original_content:\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(content)\n",
    "            return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Find and update all Python files\n",
    "files_updated = 0\n",
    "files_checked = 0\n",
    "\n",
    "# Process agents directory first (most likely to contain ray imports)\n",
    "agents_dir = finrl_meta_path / \"agents\"\n",
    "if agents_dir.exists():\n",
    "    print(f\"Processing agents directory: {agents_dir}\")\n",
    "    for py_file in agents_dir.glob(\"**/*.py\"):\n",
    "        files_checked += 1\n",
    "        if update_ray_imports(py_file):\n",
    "            files_updated += 1\n",
    "            print(f\"Updated: {py_file}\")\n",
    "\n",
    "# Then check the rest of the files\n",
    "for py_file in finrl_meta_path.glob(\"**/*.py\"):\n",
    "    # Skip already processed files in agents directory\n",
    "    if \"agents\" in str(py_file) and agents_dir.exists():\n",
    "        continue\n",
    "    files_checked += 1\n",
    "    if update_ray_imports(py_file):\n",
    "        files_updated += 1\n",
    "        print(f\"Updated: {py_file}\")\n",
    "\n",
    "print(f\"Checked {files_checked} files, updated {files_updated} files.\")\n",
    "print(\"FinRL-Meta code updated to work with Ray 2.x\")\n",
    "\n",
    "# Install latest Ray version to ensure compatibility\n",
    "import sys\n",
    "print(f\"Current Python version: {sys.version}\")\n",
    "#!pip install \"ray[rllib]>=2.0.0\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u8KdIcwH59J",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from agents.elegantrl_models import DRLAgent as DRLAgent_erl\n",
    "from agents.rllib_models import DRLAgent as DRLAgent_rllib\n",
    "from agents.stablebaselines3_models import DRLAgent as DRLAgent_sb3\n",
    "from meta.data_processor import DataProcessor\n",
    "\n",
    "def train(start_date, end_date, ticker_list, data_source, time_interval, \n",
    "          technical_indicator_list, drl_lib, env, model_name, if_vix=True,\n",
    "          **kwargs):\n",
    "    \n",
    "    #process data using unified data processor\n",
    "    DP = DataProcessor(data_source, start_date, end_date, time_interval, **kwargs)\n",
    "    price_array, tech_array, turbulence_array = DP.run(ticker_list,\n",
    "                                                        technical_indicator_list, \n",
    "                                                        if_vix, cache=True)\n",
    "\n",
    "    data_config = {'price_array': price_array,\n",
    "                   'tech_array': tech_array,\n",
    "                   'turbulence_array': turbulence_array}\n",
    "\n",
    "    #build environment using processed data\n",
    "    env_instance = env(config=data_config)\n",
    "\n",
    "    #read parameters and load agents\n",
    "    current_working_dir = kwargs.get('current_working_dir','./'+str(model_name))\n",
    "\n",
    "    if drl_lib == 'elegantrl':\n",
    "        break_step = kwargs.get('break_step', 1e6)\n",
    "        erl_params = kwargs.get('erl_params')\n",
    "\n",
    "        agent = DRLAgent_erl(env = env,\n",
    "                             price_array = price_array,\n",
    "                             tech_array=tech_array,\n",
    "                             turbulence_array=turbulence_array)\n",
    "\n",
    "        model = agent.get_model(model_name, model_kwargs = erl_params)\n",
    "\n",
    "        trained_model = agent.train_model(model=model, \n",
    "                                          cwd=current_working_dir,\n",
    "                                          total_timesteps=break_step)\n",
    "        \n",
    "      \n",
    "    elif drl_lib == 'rllib':\n",
    "        total_episodes = kwargs.get('total_episodes', 100)\n",
    "        rllib_params = kwargs.get('rllib_params')\n",
    "\n",
    "        agent_rllib = DRLAgent_rllib(env = env,\n",
    "                       price_array=price_array,\n",
    "                       tech_array=tech_array,\n",
    "                       turbulence_array=turbulence_array)\n",
    "\n",
    "        model,model_config = agent_rllib.get_model(model_name)\n",
    "\n",
    "        model_config['lr'] = rllib_params['lr']\n",
    "        model_config['train_batch_size'] = rllib_params['train_batch_size']\n",
    "        model_config['gamma'] = rllib_params['gamma']\n",
    "\n",
    "        trained_model = agent_rllib.train_model(model=model, \n",
    "                                          model_name=model_name,\n",
    "                                          model_config=model_config,\n",
    "                                          total_episodes=total_episodes)\n",
    "        trained_model.save(current_working_dir)\n",
    "        \n",
    "            \n",
    "    elif drl_lib == 'stable_baselines3':\n",
    "        total_timesteps = kwargs.get('total_timesteps', 1e6)\n",
    "        agent_params = kwargs.get('agent_params')\n",
    "\n",
    "        agent = DRLAgent_sb3(env = env_instance)\n",
    "\n",
    "        model = agent.get_model(model_name, model_kwargs = agent_params)\n",
    "        trained_model = agent.train_model(model=model, \n",
    "                                tb_log_name=model_name,\n",
    "                                total_timesteps=total_timesteps)\n",
    "        print('Training finished!')\n",
    "        trained_model.save(current_working_dir)\n",
    "        print('Trained model saved in ' + str(current_working_dir))\n",
    "    else:\n",
    "        raise ValueError('DRL library input is NOT supported. Please check.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4sKCkoAIegn",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import DRL agents\n",
    "from agents.stablebaselines3_models import DRLAgent as DRLAgent_sb3\n",
    "from agents.rllib_models import DRLAgent as DRLAgent_rllib\n",
    "from agents.elegantrl_models import DRLAgent as DRLAgent_erl\n",
    "\n",
    "# import data processor\n",
    "from meta.data_processor import DataProcessor\n",
    "\n",
    "def test(start_date, end_date, ticker_list, data_source, time_interval,\n",
    "            technical_indicator_list, drl_lib, env, model_name, if_vix=True,\n",
    "            **kwargs):\n",
    "  \n",
    "    #process data using unified data processor\n",
    "    DP = DataProcessor(data_source, start_date, end_date, time_interval, **kwargs)\n",
    "    price_array, tech_array, turbulence_array = DP.run(ticker_list,\n",
    "                                                        technical_indicator_list, \n",
    "                                                        if_vix, cache=True)\n",
    "    \n",
    "    \n",
    "    np.save('./price_array.npy', price_array)\n",
    "    data_config = {'price_array':price_array,\n",
    "                   'tech_array':tech_array,\n",
    "                   'turbulence_array':turbulence_array}\n",
    "    #build environment using processed data\n",
    "    env_instance = env(config=data_config)\n",
    "\n",
    "    env_config = {\n",
    "        \"price_array\": price_array,\n",
    "        \"tech_array\": tech_array,\n",
    "        \"turbulence_array\": turbulence_array,\n",
    "        \"if_train\": False,\n",
    "    }\n",
    "    env_instance = env(config=env_config)\n",
    "\n",
    "    # load elegantrl needs state dim, action dim and net dim\n",
    "    net_dimension = kwargs.get(\"net_dimension\", 2 ** 7)\n",
    "    current_working_dir = kwargs.get(\"current_working_dir\", \"./\" + str(model_name))\n",
    "    print(\"price_array: \", len(price_array))\n",
    "\n",
    "    if drl_lib == \"elegantrl\":\n",
    "        episode_total_assets = DRLAgent_erl.DRL_prediction(\n",
    "            model_name=model_name,\n",
    "            cwd=current_working_dir,\n",
    "            net_dimension=net_dimension,\n",
    "            environment=env_instance,\n",
    "        )\n",
    "\n",
    "        return episode_total_assets\n",
    "\n",
    "    elif drl_lib == \"rllib\":\n",
    "        # load agent\n",
    "        episode_total_assets = DRLAgent_rllib.DRL_prediction(\n",
    "            model_name=model_name,\n",
    "            env=env,\n",
    "            price_array=price_array,\n",
    "            tech_array=tech_array,\n",
    "            turbulence_array=turbulence_array,\n",
    "            agent_path=current_working_dir,\n",
    "        )\n",
    "\n",
    "        return episode_total_assets\n",
    "\n",
    "    elif drl_lib == \"stable_baselines3\":\n",
    "        episode_total_assets = DRLAgent_sb3.DRL_prediction_load_from_file(\n",
    "            model_name=model_name, environment=env_instance, cwd=current_working_dir\n",
    "        )\n",
    "\n",
    "        return episode_total_assets\n",
    "    else:\n",
    "        raise ValueError(\"DRL library input is NOT supported. Please check.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWLiSsz3Imqf"
   },
   "source": [
    "## Multiple Cryptocurrencies Trading Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUTc4dhRIraO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class CryptoEnv:  # custom env\n",
    "    def __init__(self, config, lookback=1, initial_capital=1e6, \n",
    "                 buy_cost_pct=1e-3, sell_cost_pct=1e-3, gamma=0.99):\n",
    "        self.lookback = lookback\n",
    "        self.initial_total_asset = initial_capital\n",
    "        self.initial_cash = initial_capital\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.max_stock = 1\n",
    "        self.gamma = gamma\n",
    "        self.price_array = config['price_array']\n",
    "        self.tech_array = config['tech_array']\n",
    "        self._generate_action_normalizer()\n",
    "        self.crypto_num = self.price_array.shape[1]\n",
    "        self.max_step = self.price_array.shape[0] - lookback - 1\n",
    "        \n",
    "        # reset\n",
    "        self.time = lookback-1\n",
    "        self.cash = self.initial_cash\n",
    "        self.current_price = self.price_array[self.time]\n",
    "        self.current_tech = self.tech_array[self.time]\n",
    "        self.stocks = np.zeros(self.crypto_num, dtype=np.float32)\n",
    "\n",
    "        self.total_asset = self.cash + (self.stocks * self.price_array[self.time]).sum()\n",
    "        self.episode_return = 0.0  \n",
    "        self.gamma_return = 0.0\n",
    "        \n",
    "\n",
    "        '''env information'''\n",
    "        self.env_name = 'MulticryptoEnv'\n",
    "        self.state_dim = 1 + (self.price_array.shape[1] + self.tech_array.shape[1])*lookback\n",
    "        self.action_dim = self.price_array.shape[1]\n",
    "        self.if_discrete = False\n",
    "        self.target_return = 10\n",
    "\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        self.time = self.lookback-1\n",
    "        self.current_price = self.price_array[self.time]\n",
    "        self.current_tech = self.tech_array[self.time]\n",
    "        self.cash = self.initial_cash  # reset()\n",
    "        self.stocks = np.zeros(self.crypto_num, dtype=np.float32)\n",
    "        self.total_asset = self.cash + (self.stocks * self.price_array[self.time]).sum()\n",
    "        \n",
    "        state = self.get_state()\n",
    "        return state\n",
    "\n",
    "    def step(self, actions) -> (np.ndarray, float, bool, None):\n",
    "        self.time += 1\n",
    "        \n",
    "        price = self.price_array[self.time]\n",
    "        for i in range(self.action_dim):\n",
    "            norm_vector_i = self.action_norm_vector[i]\n",
    "            actions[i] = actions[i] * norm_vector_i\n",
    "            \n",
    "        for index in np.where(actions < 0)[0]:  # sell_index:\n",
    "            if price[index] > 0:  # Sell only if current asset is > 0\n",
    "                sell_num_shares = min(self.stocks[index], -actions[index])\n",
    "                self.stocks[index] -= sell_num_shares\n",
    "                self.cash += price[index] * sell_num_shares * (1 - self.sell_cost_pct)\n",
    "                \n",
    "        for index in np.where(actions > 0)[0]:  # buy_index:\n",
    "            if price[index] > 0:  # Buy only if the price is > 0 (no missing data in this particular date)\n",
    "                buy_num_shares = min(self.cash // price[index], actions[index])\n",
    "                self.stocks[index] += buy_num_shares\n",
    "                self.cash -= price[index] * buy_num_shares * (1 + self.buy_cost_pct)\n",
    "\n",
    "        \"\"\"update time\"\"\"\n",
    "        done = self.time == self.max_step\n",
    "        state = self.get_state()\n",
    "        next_total_asset = self.cash + (self.stocks * self.price_array[self.time]).sum()\n",
    "        reward = (next_total_asset - self.total_asset) * 2 ** -16  \n",
    "        self.total_asset = next_total_asset\n",
    "        self.gamma_return = self.gamma_return * self.gamma + reward \n",
    "        self.cumu_return = self.total_asset / self.initial_cash\n",
    "        if done:\n",
    "            reward = self.gamma_return\n",
    "            self.episode_return = self.total_asset / self.initial_cash\n",
    "        return state, reward, done, None\n",
    "\n",
    "    def get_state(self):\n",
    "        state =  np.hstack((self.cash * 2 ** -18, self.stocks * 2 ** -3))\n",
    "        for i in range(self.lookback):\n",
    "            tech_i = self.tech_array[self.time-i]\n",
    "            normalized_tech_i = tech_i * 2 ** -15\n",
    "            state = np.hstack((state, normalized_tech_i)).astype(np.float32)\n",
    "        return state\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def _generate_action_normalizer(self):\n",
    "        action_norm_vector = []\n",
    "        price_0 = self.price_array[0]\n",
    "        for price in price_0:\n",
    "            x = math.floor(math.log(price, 10)) #the order of magnitude \n",
    "            action_norm_vector.append(1/((10)**x)) \n",
    "            \n",
    "        action_norm_vector = np.asarray(action_norm_vector) * 10000\n",
    "        self.action_norm_vector = np.asarray(action_norm_vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8YsfqhOGBaf"
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2uDrp5uFM3t"
   },
   "outputs": [],
   "source": [
    "TICKER_LIST = ['BTCUSDT','ETHUSDT','ADAUSDT','BNBUSDT','XRPUSDT',\n",
    "                'SOLUSDT','DOTUSDT', 'DOGEUSDT','AVAXUSDT','UNIUSDT']\n",
    "env = CryptoEnv\n",
    "TRAIN_START_DATE = '2021-09-01'\n",
    "TRAIN_END_DATE = '2021-09-02'\n",
    "\n",
    "TEST_START_DATE = '2021-09-21'\n",
    "TEST_END_DATE = '2021-09-30'\n",
    "\n",
    "INDICATORS = ['macd', 'rsi', 'cci', 'dx'] #self-defined technical indicator list is NOT supported yet\n",
    "\n",
    "ERL_PARAMS = {\"learning_rate\": 2**-15,\"batch_size\": 2**11,\n",
    "                \"gamma\": 0.99, \"seed\":312,\"net_dimension\": 2**9, \n",
    "                \"target_step\": 5000, \"eval_gap\": 30, \"eval_times\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFar1DpfGFvP"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 936
    },
    "id": "Hwt2kM5pFPiK",
    "outputId": "1aeba427-a555-4a95-c137-843edcf4c04d"
   },
   "outputs": [],
   "source": [
    "train(start_date=TRAIN_START_DATE, \n",
    "      end_date=TRAIN_END_DATE,\n",
    "      ticker_list=TICKER_LIST, \n",
    "      data_source='binance',\n",
    "      time_interval='5m', \n",
    "      technical_indicator_list=INDICATORS,\n",
    "      drl_lib='elegantrl', \n",
    "      env=env, \n",
    "      model_name='ppo', \n",
    "      current_working_dir='./test_ppo',\n",
    "      erl_params=ERL_PARAMS,\n",
    "      break_step=5e4,\n",
    "      if_vix=False\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y7bIQdkGLLU"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44EXeZglFS8d"
   },
   "outputs": [],
   "source": [
    "account_value_erl = test(start_date = TEST_START_DATE, \n",
    "                        end_date = TEST_END_DATE,\n",
    "                        ticker_list = TICKER_LIST, \n",
    "                        data_source = 'binance',\n",
    "                        time_interval= '5m', \n",
    "                        technical_indicator_list= INDICATORS,\n",
    "                        drl_lib='elegantrl', \n",
    "                        env=env, \n",
    "                        model_name='ppo', \n",
    "                        current_working_dir='./test_ppo', \n",
    "                        net_dimension = 2**9, \n",
    "                        if_vix=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSQ8YMCZGN1H"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fInPrpp6QoKK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "#calculate agent returns\n",
    "account_value_erl = np.array(account_value_erl)\n",
    "agent_returns = account_value_erl/account_value_erl[0]\n",
    "#calculate buy-and-hold btc returns\n",
    "price_array = np.load('./price_array.npy')\n",
    "btc_prices = price_array[:,0]\n",
    "buy_hold_btc_returns = btc_prices/btc_prices[0]\n",
    "#calculate equal weight portfolio returns\n",
    "price_array = np.load('./price_array.npy')\n",
    "initial_prices = price_array[0,:]\n",
    "# Make sure we only use as many tickers as we have price data for\n",
    "num_assets = min(price_array.shape[1], len(TICKER_LIST))\n",
    "print(f\"Using {num_assets} assets out of {len(TICKER_LIST)} tickers\")\n",
    "\n",
    "# Calculate equal weight (100k initial investment)\n",
    "initial_investment = 1e5\n",
    "# Equal weight means we invest initial_investment / num_assets in each asset\n",
    "investment_per_asset = initial_investment / num_assets\n",
    "# Calculate how many units of each asset we buy\n",
    "equal_weight = np.array([investment_per_asset / initial_prices[i] for i in range(num_assets)])\n",
    "equal_weight_values = []\n",
    "for i in range(0, price_array.shape[0]):\n",
    "    equal_weight_values.append(np.sum(equal_weight * price_array[i]))\n",
    "equal_weight_values = np.array(equal_weight_values)\n",
    "equal_returns = equal_weight_values/equal_weight_values[0]\n",
    "#plot \n",
    "plt.figure(dpi=200)\n",
    "plt.grid()\n",
    "plt.grid(which='minor', axis='y')\n",
    "plt.title('Cryptocurrency Trading ', fontsize=20)\n",
    "plt.plot(agent_returns, label='ElegantRL Agent', color = 'red')\n",
    "plt.plot(buy_hold_btc_returns, label='Buy-and-Hold BTC', color='blue')\n",
    "plt.plot(equal_returns, label='Equal Weight Portfolio', color='green')\n",
    "plt.ylabel('Return', fontsize=16)\n",
    "plt.xlabel('Times (5min)', fontsize=16)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "'''ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(210))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(21))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter([]))'''\n",
    "plt.legend(fontsize=10.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuI8e3JK08Iw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Demo_MultiCrypto_Trading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "finrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}